<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Runji Lin's Homepage</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: auto;
            display: flex;
            flex-direction: column;
        }
        .profile-header {
            display: flex;
            align-items: center;
            margin-bottom: 40px;
        }
        .profile-header img {
            border-radius: 50%;
            margin-right: 20px;
            width: 110px; /* Adjust based on your image */
            height: 100px; /* Maintain aspect ratio */
        }
        .profile-details {
            flex: 1;
        }
        header h1, header p {
            margin: 0;
        }
        header h1 {
            color: #0056b3;
        }
        header p {
            color: #666;
        }
        .section {
            margin-bottom: 30px;
        }
        .section h2 {
            color: #0056b3;
            border-bottom: 2px solid #0056b3;
            padding-bottom: 5px;
        }
        .publication, .bio, .experience {
            margin-bottom: 15px;
        }
        .publication h3, .bio h3, .experience h3 {
            margin: 5px 0;
            color: #333;
        }
        .publication p, .bio p, .experience p {
            margin: 0;
            color: #666;
        }
        a {
            text-decoration: none;
            color: #0056b3;
        }
        a:hover {
            text-decoration: underline;
        }
        .footer {
            text-align: center;
            margin-top: 50px;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="profile-header">
            
            <div class="profile-details">
                <h1>Runji Lin</h1>
                <p>Email: linrunji2021 [at] ia.ac.cn</p>
                <p>Fields of Interest: Reinforcement Learning, Multi-Agent System, Large Language Models</p>
            </div>
            <img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=_8YDMC0AAAAJ&citpid=2" alt="Runji Lin">
        </div>
        <div class="section bio">
            <h2>Short Bio</h2>
            <p>Runji Lin is currently pursuing his MSc degree at the School of Artificial Intelligence, University of Chinese Academy of Sciences, China. His research interests include reinforcement learning, multi-agent system, and Large Language Models. He participated in the development of the Qwen series of large language models, mainly involving in the RLHF alignment of LLM, as well as the development of integrating large models as agents with external systems.</p>
        </div>
        <div class="section">
            <h2>Experience</h2>
            <div class="experience">
                <h3>Research Intern at Alibaba Qwen Team</h3>
                <p>2022.11 - Present</p>
            </div>
            <div class="experience">
                <h3>Algorithm Engineer Intern at NetEase</h3>
                <p>2020.07 - 2020.08</p>
            </div>
            <!-- More experiences can be added here -->
        </div>
        <div class="section">
          <h2>Publications</h2>
          <!-- Publication 1 -->
          <div class="publication">
              <h3>Large language models play starcraft ii: Benchmarks and a chain of summarization approach</h3>
              <p>W Ma, Q Mi, X Yan, Y Wu, <strong>R Lin</strong>, H Zhang, J Wang arXiv preprint</p>
              <p>arXiv:2312.11865, 2023 -  <a href="https://arxiv.org/abs/2312.11865" target="_blank">View Paper</a></p>
          </div>
          <!-- Publication 2 -->
          <div class="publication">
            <h3>Routing to the expert: Efficient reward-guided ensemble of large language models</h3>
            <p>K Lu, H Yuan, <strong>R Lin</strong>, J Lin, Z Yuan, C Zhou, J Zhou</p>
            <p>arXiv preprint - arXiv:2311.08692, 2023 - <a href="https://arxiv.org/abs/2311.08692" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 3 -->
        <div class="publication">
            <h3># InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models</h3>
            <p>K Lu, H Yuan, Z Yuan, <strong>R Lin</strong>, J Lin, C Tan, C Zhou, J Zhou</p>
            <p> ICLR 2023 - <a href="https://openreview.net/pdf?id=pszewhybU9" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 4 -->
        <div class="publication">
            <h3>Qwen technical report</h3>
            <p>J Bai, S Bai, Y Chu, Z Cui, K Dang, X Deng, Y Fan, W Ge, Y Han, F Huang, <strong>R Lin</strong>...</p>
            <p>arXiv preprint - arXiv:2309.16609, 2023 - <a href="https://arxiv.org/abs/2309.16609" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 5 -->
        <div class="publication">
            <h3>Learn to Flap: Foil Non-parametric Path Planning via Deep Reinforcement Learning</h3>
            <p>ZP Wang*, RJ Lin*, ZY Zhao, PM Guo, N Yang, DX Fan</p>
            <p> Journal of Fluid Mechanics, 2023 - <a href="https://arxiv.org/abs/2305.12687" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 6 -->
        <div class="publication">
            <h3>Large Sequence Models for Sequential Decision-Making: A Survey</h3>
            <p>M WEN*, <strong>R Lin*</strong>, H WANG, Y YANG, Y WEN, L MAI, J WANG, H ZHANG, ...</p>
            <p>Frontiers of Computer Science, 2023 - <a href="https://arxiv.org/pdf/2306.13945" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 7 -->
        <div class="publication">
            <h3>Contextual Transformer for Offline Meta Reinforcement Learning</h3>
            <p><strong>R Lin</strong>, Y Li, X Feng, Z Zhang, XHW Fung, H Zhang, J Wang, Y Du, Y Yang</p>
            <p>NeurIPS 2022 Workshop: Foundation Models for Decision Making, 2022 - <a href="https://arxiv.org/pdf/2211.08016" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 8 -->
        <div class="publication">
            <h3>Scalable Model-based Policy Optimization for Decentralized Networked Systems</h3>
            <p>Y Du, C Ma, Y Liu, <strong>R Lin</strong>, H Dong, J Wang, Y Yang</p>
            <p>IROS 2022 - <a href="https://discovery.ucl.ac.uk/id/eprint/10164561/1/2207.06559.pdf" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 9 -->
        <div class="publication">
            <h3>Multi-Agent Reinforcement Learning is a Sequence Modeling Problem</h3>
            <p>M Wen, JG Kuba, <strong>R Lin</strong>, W Zhang, Y Wen, J Wang, Y Yang</p>
            <p>NeurIPS 2022 - <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/69413f87e5a34897cd010ca698097d0a-Paper-Conference.pdf" target="_blank">View Paper</a></p>
        </div>

        <!-- Publication 10 -->
        <div class="publication">
            <h3>Increasing the Data Rate for Reflected Optical Camera Communication Using Uniform LED Light</h3>
            <p>Z Chen*, <strong>R Lin*</strong>, H Duan, Y Chen, Y Yang, R Wu, L Chen</p>
            <p>IEEE INFOCOM 2020-IEEE Conference on Computer Communications Workshops, 2020 - <a href="https://seaxiaod.gitee.io/publications/2020/INFOCOM2020Inc.pdf" target="_blank">View Paper</a></p>
        </div>

          <!-- More publications can be added here following the same structure -->
        </div>
        <div class="footer">
            <p>&copy; 2024 Runji Lin. All rights reserved.</p>
        </div>
    </div>
</body>
</html>
